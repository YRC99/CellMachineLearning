{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi Rui Cui\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\anndata\\compat\\__init__.py:183: FutureWarning: Moving element from .uns['neighbors']['distances'] to .obsp['distances'].\n",
      "\n",
      "This is where adjacency matrices should go now.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import scanpy\n",
    "\n",
    "adata = scanpy.read_h5ad(\"pbmc_multimodal.h5ad\")\n",
    "dataset=adata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Outputs that might be helpful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161764\n",
      "20729\n",
      "(161764, 20729)\n",
      "Index(['nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA',\n",
      "       'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2',\n",
      "       'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'],\n",
      "      dtype='object')\n",
      "Index(['features'], dtype='object')\n",
      "(161764, 14)\n",
      "(20729, 1)\n"
     ]
    }
   ],
   "source": [
    "#print(adata.X[0])\n",
    "print(len(adata.obs_names.tolist()))\n",
    "print(len(adata.var_names.tolist()))\n",
    "print(adata.shape)\n",
    "print(adata.obs.keys())\n",
    "print(adata.var.keys())\n",
    "print(adata.obs.shape)\n",
    "print(adata.var.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the base dataset for the model (Preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161764, 14)\n",
      "Index(['nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA',\n",
      "       'orig.ident', 'lane', 'donor', 'time', 'celltype.l1', 'celltype.l2',\n",
      "       'celltype.l3', 'Phase', 'nCount_SCT', 'nFeature_SCT'],\n",
      "      dtype='object')\n",
      "Index(['nCount_ADT', 'nFeature_ADT', 'nCount_RNA', 'nFeature_RNA',\n",
      "       'celltype.l1', 'celltype.l2', 'celltype.l3', 'Phase', 'nCount_SCT',\n",
      "       'nFeature_SCT'],\n",
      "      dtype='object')\n",
      "(161764, 10)\n",
      "                     nCount_ADT  nFeature_ADT  nCount_RNA  nFeature_RNA  \\\n",
      "L1_AAACCCAAGAAACTCA      7430.0           221     10823.0          2915   \n",
      "L1_AAACCCAAGACATACA      5949.0           211      5864.0          1617   \n",
      "L1_AAACCCACAACTGGTT      6547.0           217      5067.0          1381   \n",
      "L1_AAACCCACACGTACTA      3508.0           207      4786.0          1890   \n",
      "L1_AAACCCACAGCATACT      6318.0           219      6505.0          1621   \n",
      "\n",
      "                    celltype.l1 celltype.l2 celltype.l3 Phase  nCount_SCT  \\\n",
      "L1_AAACCCAAGAAACTCA        Mono   CD14 Mono   CD14 Mono    G1      6380.0   \n",
      "L1_AAACCCAAGACATACA       CD4 T     CD4 TCM   CD4 TCM_1    G1      5693.0   \n",
      "L1_AAACCCACAACTGGTT       CD8 T   CD8 Naive   CD8 Naive     S      5066.0   \n",
      "L1_AAACCCACACGTACTA          NK          NK        NK_2    G1      4984.0   \n",
      "L1_AAACCCACAGCATACT       CD8 T   CD8 Naive   CD8 Naive    G1      5854.0   \n",
      "\n",
      "                     nFeature_SCT  \n",
      "L1_AAACCCAAGAAACTCA          2548  \n",
      "L1_AAACCCAAGACATACA          1615  \n",
      "L1_AAACCCACAACTGGTT          1379  \n",
      "L1_AAACCCACACGTACTA          1889  \n",
      "L1_AAACCCACAGCATACT          1620  \n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)\n",
    "print(dataset.keys())\n",
    "#Maybe also drop celltype.l2 and celltype.l3\n",
    "cleanedDataset=dataset.drop(['time','donor','lane','orig.ident'],axis=1)\n",
    "print(cleanedDataset.keys())\n",
    "print(cleanedDataset.shape)\n",
    "print(cleanedDataset.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and sklearn version (useful for debugging purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting preprocessed dataset into X (samples) and y (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161764, 10)\n",
      "(161764, 1)\n",
      "(161764, 8)\n",
      "                     celltype.l1_B  celltype.l1_CD4 T  celltype.l1_CD8 T  \\\n",
      "L1_AAACCCAAGAAACTCA              0                  0                  0   \n",
      "\n",
      "                     celltype.l1_DC  celltype.l1_Mono  celltype.l1_NK  \\\n",
      "L1_AAACCCAAGAAACTCA               0                 1               0   \n",
      "\n",
      "                     celltype.l1_other  celltype.l1_other T  \n",
      "L1_AAACCCAAGAAACTCA                  0                    0  \n",
      "(161764, 7)\n",
      "(161764, 9)\n",
      "                     nCount_ADT  nFeature_ADT  nCount_RNA  nFeature_RNA  \\\n",
      "L1_AAACCCAAGAAACTCA      7430.0           221     10823.0          2915   \n",
      "\n",
      "                     nCount_SCT  nFeature_SCT  Phase_G1  Phase_G2M  Phase_S  \n",
      "L1_AAACCCAAGAAACTCA      6380.0          2548         1          0        0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(cleanedDataset.shape)\n",
    "classes = cleanedDataset[['celltype.l1']]\n",
    "print(classes.shape)\n",
    "print(pd.get_dummies(classes).shape)\n",
    "print(pd.get_dummies(classes).head(1))\n",
    "classes=pd.get_dummies(classes)\n",
    "samples=cleanedDataset.drop(['celltype.l1','celltype.l2','celltype.l3'],axis=1)\n",
    "print(samples.shape)\n",
    "print(pd.get_dummies(samples).shape)\n",
    "print(pd.get_dummies(samples).head(1))\n",
    "samples=pd.get_dummies(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating X_train, X_test, y_train and y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and test set\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting data into training and test set\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    samples, classes, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Classifier for baseline comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of original X and y\t(161764, 9)\t\t(161764, 8)\n",
      "shapes of test X and y\t\t(48530, 9)\t\t(48530, 8)\n",
      "shapes of training X and y\t(113234, 9)\t\t(113234, 8)\n",
      "Beginning fitting of model\n",
      "Model has been fit, starting prediction\n",
      "Accuracy:\t 0.08961467133731713\n",
      "F1-Score:\t 0.12604227524023495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "dummy = DummyClassifier(random_state=0, strategy='stratified')\n",
    "print(\"shapes of original X and y\\t{}\\t\\t{}\".format(samples.shape, classes.shape))\n",
    "print(\"shapes of test X and y\\t\\t{}\\t\\t{}\".format(X_test.shape, y_test.shape))\n",
    "print(\"shapes of training X and y\\t{}\\t\\t{}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Beginning fitting of model\")\n",
    "dummy.fit(X_train, y_train)\n",
    "print(\"Model has been fit, starting prediction\")\n",
    "y_pred = dummy.predict(X_test)\n",
    "print(\"Accuracy:\\t\", float(accuracy_score(y_test, y_pred)))\n",
    "print(\"F1-Score:\\t\", f1_score(y_test, y_pred, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes of original X and y\t(161764, 9)\t\t(161764, 8)\n",
      "shapes of test X and y\t\t(48530, 9)\t\t(48530, 8)\n",
      "shapes of training X and y\t(113234, 9)\t\t(113234, 8)\n",
      "Beginning fitting of model\n",
      "Model has been fit, starting prediction\n",
      "(48530, 8)\n",
      "Accuracy:\t0.5983103235112301\t\tF1-Score:\t0.5341668474494423\n",
      "[[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=500, n_jobs=-1, random_state=0)\n",
    "print(\"shapes of original X and y\\t{}\\t\\t{}\".format(samples.shape, classes.shape))\n",
    "print(\"shapes of test X and y\\t\\t{}\\t\\t{}\".format(X_test.shape, y_test.shape))\n",
    "print(\"shapes of training X and y\\t{}\\t\\t{}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Beginning fitting of model\")\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Model has been fit, starting prediction\")\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(y_pred.shape)\n",
    "print(\"Accuracy:\\t{}\\t\\tF1-Score:\\t{}\".format(accuracy, f1))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model using pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(clf,open(\"model.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, 'model.joblib')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5865cc53dc1011e62ac625d2b2cdb51438fa37126506e6c30203d699e51b3c2b"
  },
  "kernelspec": {
   "display_name": "Python 3.6.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
